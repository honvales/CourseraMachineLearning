---
title: "Final project"
author: "Honorio Valdes"
date: "8/2/2020"
output: html_document
---

## Summary
This project explores a data set (Ugulino et al, 2012) including accelerometer data for 6 different users and aims to predict whether a user performed barbell lifts correctly. A random forest model combined with 5-fold cross validation was used to classify each of the observations into 5 categories: A (according to specification), B (throwing elbows to the front), C (lifting the dumbbell only halfway), D (lowering dumbbell only halfway), and E (throwing hips to the front). The model was able to achieved a 99.5% accuracy on the validation set and identified all 20 observations on the test set correctly.

## Loading data
The following code shows how the data was imported.
```{r data import,cache=TRUE}
trainfil <- download.file('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv','pml-training.csv')
traindata <- read.csv('pml-training.csv')
testfil <- download.file('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv','pml-test.csv')
testdata <- read.csv('pml-test.csv')
```

## Exploratory Analysis
Due to the large amount of variables, no plots were included in the exploratory analysis. A summary for the training data is shown below. There are several columns that have constant values or character data types that might not contribute to the model. However, it is necessary to know how the type and quality of data compares between the training and testing data sets.
```{r summ_train}
summary(traindata)
```

A summary of the testing data is shown below. Visual inspection shows that there are multiple columns with all values missing. These columns were removed from both the training and test data sets, as described in the following section.
```{r summ_test}
summary(testdata)
```

## Data preprocessing and cleaning
Prior to analysis, a count of missing values was performed to eliminate rows that will not contribute to the test data set predictions. Out of the 160 variables, it was possible to reduce the count to 60 (59 variables + the predictor). Among these 60 variables, it was possible to further remove columns such as the time, date, and user names. This led to a further reduction to 53 variables (the predictor + 52 classifiers). Other strategies to further reduce the number of predictors were attempted such as determination of zero variate determination, but analysis determined the absence of zero variates. 
```{r NA_vals}
delcols <- colnames(testdata)[colSums(is.na(testdata))>0]
cleantest <- testdata[,!(names(testdata) %in% delcols)][,c(8:59)]
cleantrain <- traindata[,!(names(traindata) %in% delcols)][,c(8:60)]
```

## Building the model
A random forest model was used to predict the data using 5-fold cross validation. This model was chosen as it combines the output of multiple trees to create a stronger predictor. In addition, cross validation was used to prevent overfitting and for time efficiency. Using these parameters, a 15 minute execution time was achieved for an early 2013 MacBook Pro (3 GHz processor).
```{r model,cache=TRUE}
fitControl <- trainControl(method='cv',number=5)
rfmod <- train(factor(classe) ~ .,method='rf', data=training,trControl=fitControl,verbose=FALSE)
```

### Model error discussion
The model results are summarized below and show that the model has a prediction error of 0.7%. 
```{r summ_mod}
rfmod
```

Furthermore, the model struggles to categorize some observations more than others. For example, the classification error for category D is 1.7% and is 2 to 10 times larger than that of the other categories. Meanwhile, the error for the other categories ranges between 0.1% and 0.9%
```{r var_err}
errtable <- rfmod$finalModel[['err.rate']]
rbind(OOB = mean(errtable[,'OOB']),A = mean(errtable[,'A']),B = mean(errtable[,'B']),C = mean(errtable[,'C']),D = mean(errtable[,'D']),E = mean(errtable[,'E']))
```

## Model predictions
The model described previously was then used to predict the 20 observations in the cleantest data frame and submitted to the final course quiz for grading, predicting all observations correctly. Due to academic honesty concerns and as requested by the instructors, the results are not shown in this document. The code below was used to predict the results.
```{r preds}
preds <- predict(rfmod,cleantest)
```
